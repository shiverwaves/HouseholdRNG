name: Combined Data Import (Census + OEWS)

on:
  # Run quarterly on the 1st at 2 AM UTC (Census data updates annually, OEWS more frequently)
  schedule:
    - cron: '0 2 1 */3 *'  # Every 3 months
  
  # Allow manual trigger with options
  workflow_dispatch:
    inputs:
      import_census:
        description: 'Import Census demographic data'
        required: false
        default: true
        type: boolean
      import_oews:
        description: 'Import OEWS employment/wage data'
        required: false
        default: true
        type: boolean
      force_download:
        description: 'Force download and import even if data exists'
        required: false
        default: false
        type: boolean

jobs:
  import-census-data:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    if: github.event.inputs.import_census != 'false'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Create environment file
      run: |
        echo "NEON_CONNECTION_STRING=${{ secrets.NEON_CONNECTION_STRING }}" > .env
        echo "CENSUS_API_KEY=${{ secrets.CENSUS_API_KEY }}" >> .env
        
    - name: Verify database connection
      run: |
        python -c "
        import os, psycopg2
        from dotenv import load_dotenv
        load_dotenv()
        conn = psycopg2.connect(os.getenv('NEON_CONNECTION_STRING'))
        print('✅ Database connection successful')
        conn.close()
        "
        
    - name: Check if census data exists
      id: check_census_data
      run: |
        python -c "
        import os, psycopg2
        from dotenv import load_dotenv
        load_dotenv()
        
        try:
            conn = psycopg2.connect(os.getenv('NEON_CONNECTION_STRING'))
            with conn.cursor() as cur:
                # Check if census tables exist and have data
                cur.execute('''
                    SELECT COUNT(*) FROM information_schema.tables 
                    WHERE table_schema = 'public' AND table_name = 'state_demographics'
                ''')
                table_exists = cur.fetchone()[0] > 0
                
                if table_exists:
                    cur.execute('''
                        SELECT 
                            COUNT(*) as states,
                            COUNT(*) FILTER (WHERE total_population > 0) as states_with_pop,
                            MAX(data_year) as latest_year
                        FROM state_demographics 
                    ''')
                    states, states_with_pop, latest_year = cur.fetchone()
                    
                    cur.execute('SELECT COUNT(*) FROM state_race_ethnicity')
                    race_records = cur.fetchone()[0]
                    
                    cur.execute('SELECT COUNT(*) FROM state_employment_stats')
                    employment_records = cur.fetchone()[0]
                    
                    if (states >= 50 and states_with_pop >= 50 and 
                        race_records >= 300 and employment_records >= 40 and
                        latest_year and latest_year >= 2022):
                        print(f'Found {states} states, {race_records} race records, {employment_records} employment records')
                        print(f'Latest data year: {latest_year}')
                        print('has_census_data=true')
                    else:
                        print(f'Insufficient data: {states} states, {race_records} race records, year {latest_year}')
                        print('has_census_data=false')
                else:
                    print('Census tables do not exist')
                    print('has_census_data=false')
            
            conn.close()
            
        except Exception as e:
            print(f'Database check failed: {e}')
            print('has_census_data=false')
        " > census_check_result.txt
        
        if grep -q "has_census_data=true" census_check_result.txt; then
          echo "has_data=true" >> $GITHUB_OUTPUT
        else
          echo "has_data=false" >> $GITHUB_OUTPUT
        fi
        
    - name: Skip census import if data exists (unless forced)
      if: steps.check_census_data.outputs.has_data == 'true' && github.event.inputs.force_download != 'true'
      run: |
        echo "⏭️ Census demographic data already exists in database"
        echo "Found complete state-level demographic data for 50+ states."
        echo "To force re-download, use manual trigger with force_download=true"
        
    - name: Import census demographic data
      if: steps.check_census_data.outputs.has_data != 'true' || github.event.inputs.force_download == 'true'
      run: |
        echo "🏛️ Starting Census demographic data import..."
        python get_fam_hh_data.py
        
    - name: Verify census import success
      if: steps.check_census_data.outputs.has_data != 'true' || github.event.inputs.force_download == 'true'
      run: |
        python -c "
        import os, psycopg2
        from dotenv import load_dotenv
        load_dotenv()
        
        conn = psycopg2.connect(os.getenv('NEON_CONNECTION_STRING'))
        with conn.cursor() as cur:
            # Get summary statistics
            cur.execute('''
                SELECT 
                    COUNT(*) as states,
                    SUM(total_population) as total_us_pop,
                    MAX(data_year) as data_year,
                    COUNT(*) FILTER (WHERE total_population > 0) as states_with_pop
                FROM state_demographics 
            ''')
            states, total_pop, year, states_with_pop = cur.fetchone()
            
            cur.execute('SELECT COUNT(*) FROM state_race_ethnicity')
            race_records = cur.fetchone()[0]
            
            cur.execute('SELECT COUNT(*) FROM state_employment_stats') 
            employment_records = cur.fetchone()[0]
            
            cur.execute('SELECT COUNT(*) FROM state_family_structures')
            family_records = cur.fetchone()[0]
            
            print('📊 CENSUS DATA IMPORT SUMMARY:')
            print(f'{states} states | {total_pop:,} total population | Year {year}')
            print(f'{race_records} race records | {employment_records} employment records | {family_records} family structure records')
            
            # Validation
            if states < 50:
                raise Exception(f'Import verification failed: only {states} states found')
            if race_records < 300:  # 50 states * 6+ race categories
                raise Exception(f'Import verification failed: only {race_records} race records found')
            if employment_records < 40:  # Should have employment data for most states
                raise Exception(f'Import verification failed: only {employment_records} employment records found')
                
            print(f'✅ Census import verification successful')
        
        conn.close()
        "

  import-oews-data:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    if: github.event.inputs.import_oews != 'false'
    needs: [import-census-data]  # Run after census import
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Create environment file
      run: |
        echo "NEON_CONNECTION_STRING=${{ secrets.NEON_CONNECTION_STRING }}" > .env
        
    - name: Verify database connection
      run: |
        python -c "
        import os, psycopg2
        from dotenv import load_dotenv
        load_dotenv()
        conn = psycopg2.connect(os.getenv('NEON_CONNECTION_STRING'))
        print('✅ Database connection successful')
        conn.close()
        "
        
    - name: Check if OEWS data exists
      id: check_oews_data
      run: |
        python -c "
        import os, psycopg2
        from dotenv import load_dotenv
        load_dotenv()
        
        try:
            conn = psycopg2.connect(os.getenv('NEON_CONNECTION_STRING'))
            with conn.cursor() as cur:
                # Check if OEWS table exists and has state data
                cur.execute('''
                    SELECT COUNT(*) FROM information_schema.tables 
                    WHERE table_schema = 'oews' AND table_name = 'employment_wages'
                ''')
                table_exists = cur.fetchone()[0] > 0
                
                if table_exists:
                    cur.execute('''
                        SELECT COUNT(*), COUNT(DISTINCT area_title), MAX(year)
                        FROM oews.employment_wages 
                    ''')
                    count, states, latest_year = cur.fetchone()
                    
                    if count and count > 30000 and states and states >= 50 and latest_year and latest_year >= 2023:
                        print(f'Found {count:,} records across {states} states, year {latest_year}')
                        print('has_oews_data=true')
                    else:
                        print(f'Insufficient data: {count} records, {states} states, year {latest_year}')
                        print('has_oews_data=false')
                else:
                    print('OEWS table does not exist')
                    print('has_oews_data=false')
            
            conn.close()
            
        except Exception as e:
            print(f'Database check failed: {e}')
            print('has_oews_data=false')
        " > oews_check_result.txt
        
        if grep -q "has_oews_data=true" oews_check_result.txt; then
          echo "has_data=true" >> $GITHUB_OUTPUT
        else
          echo "has_data=false" >> $GITHUB_OUTPUT
        fi
        
    - name: Skip OEWS import if data exists (unless forced)
      if: steps.check_oews_data.outputs.has_data == 'true' && github.event.inputs.force_download != 'true'
      run: |
        echo "⏭️ OEWS employment/wage data already exists in database"
        echo "Found substantial data across 50+ states. Skipping download."
        echo "To force re-download, use manual trigger with force_download=true"
        
    - name: Download and import OEWS data
      if: steps.check_oews_data.outputs.has_data != 'true' || github.event.inputs.force_download == 'true'
      run: |
        echo "🚀 Starting OEWS employment/wage data download and import..."
        python get_emp_wages_data.py
        
    - name: Verify OEWS import success
      if: steps.check_oews_data.outputs.has_data != 'true' || github.event.inputs.force_download == 'true'
      run: |
        python -c "
        import os, psycopg2
        from dotenv import load_dotenv
        load_dotenv()
        
        conn = psycopg2.connect(os.getenv('NEON_CONNECTION_STRING'))
        with conn.cursor() as cur:
            # Get summary statistics
            cur.execute('''
                SELECT 
                    year,
                    COUNT(*) as total_records,
                    COUNT(DISTINCT area_title) as states,
                    COUNT(DISTINCT occ_code) as occupations,
                    COUNT(*) FILTER (WHERE a_median IS NOT NULL) as records_with_wages
                FROM oews.employment_wages 
                GROUP BY year
                ORDER BY year DESC
                LIMIT 1
            ''')
            
            result = cur.fetchone()
            if result:
                year, records, states, occs, wage_records = result
                print('📊 OEWS DATA IMPORT SUMMARY:')
                print(f'{records:,} records | {states} states | {occs} occupations | {wage_records:,} with wages')
                
                # Validation
                if records < 30000:
                    raise Exception(f'Import verification failed: only {records:,} records found')
                if states < 50:
                    raise Exception(f'Import verification failed: only {states} states found')
                    
                print(f'✅ OEWS import verification successful: {records:,} records across {states} states')
            else:
                raise Exception('No OEWS data found after import')
        
        conn.close()
        "

  # Test family generation after successful imports
  test-family-generation:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [import-census-data, import-oews-data]
    if: always() && (needs.import-census-data.result == 'success' || needs.import-census-data.result == 'skipped')
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Create environment file
      run: |
        echo "NEON_CONNECTION_STRING=${{ secrets.NEON_CONNECTION_STRING }}" > .env
        
    - name: Test family generation
      run: |
        echo "🏠 Testing family generation with imported data..."
        python fam_hh_gen.py --count 5
        
    - name: Test state-specific generation
      run: |
        echo "🏠 Testing state-specific family generation..."
        python fam_hh_gen.py --state California --count 3

  cleanup:
    runs-on: ubuntu-latest
    needs: [import-census-data, import-oews-data, test-family-generation]
    if: always()
    
    steps:
    - name: Cleanup and summary
      run: |
        echo "🧹 Data import workflow completed"
        echo "Census import: ${{ needs.import-census-data.result }}"
        echo "OEWS import: ${{ needs.import-oews-data.result }}"
        echo "Family generation test: ${{ needs.test-family-generation.result }}"
        
    - name: Upload logs on failure
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: combined-import-logs
        path: |
          census_check_result.txt
          oews_check_result.txt
        retention-days: 7
